# -*- coding: utf-8 -*-
"""ML_LAB_09.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XkLXUzBdlvjXKOc3fXq8KpSJ6v--CKkA

Name:Harsh Pandit

Roll No:H036

Program : Mechatronics

Division:H

Batch: H1

Date of Experiment: 17/02/2022

Date of Submission: 25/02/2022
"""

#importing all relevant libraries
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve,roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier

#reading the csv file
df=pd.read_csv('diabetes.csv')
df.head()

#replacing 0 values with mean
l=[]
for i in range (0,len(df['BloodPressure'])):
  if df['BloodPressure'].iloc[i]==np.nan:
    df['BloodPressure'].iloc[i]=0
for i in df['BloodPressure']:
  if i!=0:
    l.append(i)
mean=sum(l)
mean=sum(l)/len(l)
for i in range (0,len(df['BloodPressure'])):
  if df['BloodPressure'].iloc[i]==0:
    df['BloodPressure'].iloc[i]=mean

#replacing 0 values with mean
l=[]
for i in range (0,len(df['Glucose'])):
  if df['Glucose'].iloc[i]==np.nan:
    df['Glucose'].iloc[i]=0
for i in df['Glucose']:
  if i!=0:
    l.append(i)
mean=sum(l)
mean=sum(l)/len(l)
for i in range (0,len(df['Glucose'])):
  if df['Glucose'].iloc[i]==0:
    df['Glucose'].iloc[i]=mean

l=[]
for i in range (0,len(df['SkinThickness'])):
  if df['SkinThickness'].iloc[i]==np.nan:
    df['SkinThickness'].iloc[i]=0
for i in df['SkinThickness']:
  if i!=0:
    l.append(i)
mean=sum(l)
mean=sum(l)/len(l)
for i in range (0,len(df['SkinThickness'])):
  if df['SkinThickness'].iloc[i]==0:
    df['SkinThickness'].iloc[i]=mean

l=[]
for i in range (0,len(df['Insulin'])):
  if df['Insulin'].iloc[i]==np.nan:
    df['Insulin'].iloc[i]=0
for i in df['Insulin']:
  if i!=0:
    l.append(i)
mean=sum(l)
mean=sum(l)/len(l)
for i in range (0,len(df['Insulin'])):
  if df['Insulin'].iloc[i]==0:
    df['Insulin'].iloc[i]=mean

l=[]
for i in range (0,len(df['BMI'])):
  if df['BMI'].iloc[i]==np.nan:
    df['BMI'].iloc[i]=0
for i in df['BMI']:
  if i!=0:
    l.append(i)
mean=sum(l)
mean=sum(l)/len(l)
for i in range (0,len(df['BMI'])):
  if df['BMI'].iloc[i]==0:
    df['BMI'].iloc[i]=mean

#dropping roes containing null values
df=df.dropna()

df.describe()

#describing x and y values
x=df.drop('Outcome',axis=1)
y=df['Outcome']
#splitting the data
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)
#defining the model
model=GaussianNB()
#training the model
model.fit(x_train,y_train)

#finding out predicted values
y_pred=model.predict(x_test)

df1=pd.DataFrame()
df1['y']=y_test
df1['ypred']=y_pred

#predidiction the probablity for each outcome
y_pred_proba = model.predict_proba(x_test)

#taking the probablity for outcome 1
y_pred_prob=[]
for i in range (0,len(y_pred_proba)):
  y_pred_prob.append(y_pred_proba[i][1])

df1['prob']=y_pred_prob

df1.head()

#finding the number of 1 and 0 as outcomes
value_one=0
value_zero=0
for i in df['Outcome']:
  if i==1:
    value_one+=1
  if i==0:
    value_zero+=1
print(value_one)
print(value_zero)

print("Since value of 1's is not not equal to value of zeros's, hence the data is not balanced")

#finding out TP,TN,FP and FN
TP=0
TN=0
FN=0
FP=0
for i in range (0,len(df1)):
  if df1['y'].iloc[i]==df1['ypred'].iloc[i]==0:
    TN+=1
  if df1['y'].iloc[i]==df1['ypred'].iloc[i]==1:
    TP+=1
  if df1['y'].iloc[i]==0 and df1['ypred'].iloc[i]==1:
    FP+=1
  if df1['y'].iloc[i]==1 and df1['ypred'].iloc[i]==0:
    FN+=1
print('TP is',TP)
print('TN is',TN)
print('FP is',FP)
print('FN is',FN)

#printing confusion matrix
ConfusionMatrix = confusion_matrix(y_test, y_pred)
print(ConfusionMatrix)

#defining the model
model1=DecisionTreeClassifier(random_state=0)
#training the model
model1.fit(x_train,y_train)

#finding out predicted values
y_pred1=model1.predict(x_test)
df2=pd.DataFrame()
df2['y']=y_test
df2['ypred']=y_pred1

#predidiction the probablity for each outcome
y_pred_proba1 = model1.predict_proba(x_test)

#taking the probablity for outcome 1
y_pred_prob1=[]
for i in range (0,len(y_pred_proba1)):
  y_pred_prob1.append(y_pred_proba1[i][1])

df2['prob']=y_pred_prob1

#finding out TP,TN,FP and FN
TP1=0
TN1=0
FN1=0
FP1=0
for i in range (0,len(df2)):
  if df2['y'].iloc[i]==df2['ypred'].iloc[i]==0:
    TN1+=1
  if df2['y'].iloc[i]==df1['ypred'].iloc[i]==1:
    TP1+=1
  if df2['y'].iloc[i]==0 and df2['ypred'].iloc[i]==1:
    FP1+=1
  if df2['y'].iloc[i]==1 and df2['ypred'].iloc[i]==0:
    FN1+=1
print('TP is',TP1)
print('TN is',TN1)
print('FP is',FP1)
print('FN is',FN1)

#printing confusion matrix
ConfusionMatrix = confusion_matrix(y_test, y_pred1)
print(ConfusionMatrix)

#plotting the roc curve for both the models
fpr,tpr,_=roc_curve(y_test,df1['prob'])
random_probs = [0 for i in range(len(y_test))]
p_fpr, p_tpr, _ = roc_curve(y_test, random_probs)
fpr1,tpr1,_=roc_curve(y_test,df2['prob'])
plt.plot(fpr1,tpr1,color='red',label='Descison Tree')
plt.plot(p_fpr,p_tpr)
plt.plot(fpr,tpr,color='orange',label='Gaussian NB')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()

"""Conclusion: Hence the ROC curve was plotted two different classification methods. We found that AUC for Descison Tree is less than that of AUC of Gaussian NB."""